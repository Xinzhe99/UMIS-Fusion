# -*- coding: utf-8 -*-
# @Author  : XinZhe Xie
# @University  : ZheJiang University

import myloss
import time
import os
import argparse
from tqdm import tqdm
import joblib
import glob
import torch
import torch.backends.cudnn as cudnn
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from data_driven import GetDataset
import unetplusplus
from tensorboardX import SummaryWriter
def parse_args():  # 参数解析器
    parser = argparse.ArgumentParser()
    # 增加属性
    parser.add_argument('--name', default='UMIS_train',help='Output folder name')
    parser.add_argument('--epochs', default=80, type=int)
    parser.add_argument('--model_save_fre', type=int, default=10, help='model save frequence (default: 5)')
    parser.add_argument('--batch_size', default=8, type=int)
    parser.add_argument('--lr', '--learning-rate', default=1e-4, type=float)
    parser.add_argument('--gamma', default=0.9, type=float)
    parser.add_argument('--betas', default=(0.9, 0.999), type=tuple)
    parser.add_argument('--eps', default=1e-8, type=float)
    parser.add_argument('--weight-decay', default=5e-4, type=float)
    parser.add_argument('--training_dir_name',default="train_dataset",type=str)
    parser.add_argument('--test_dir_name', default="test_dataset", type=str)
    parser.add_argument('--loss_weight',default=[1,3,1,2],type=list,help='mse;ssim;gra;sf')
    parser.add_argument('--source_type_train', default='*.Bmp', type=str)
    parser.add_argument('--source_type_test', default='*.Bmp', type=str)
    args = parser.parse_args()
    return args

def main():
    args = parse_args()
    writer = SummaryWriter()
    if not os.path.exists('models/%s' % args.name):
        os.makedirs('models/%s' % args.name)
    print('Config -----')
    for arg in vars(args):
        print('%s: %s' % (arg, getattr(args, arg)))
    print('------------')
    with open('models/%s/args.txt' % args.name, 'w') as f:
        for arg in vars(args):
            print('%s: %s' % (arg, getattr(args, arg)), file=f)
    joblib.dump(args, 'models/%s/args.pkl' % args.name)
    cudnn.benchmark = True

    if torch.cuda.is_available():
        print('GPU Mode Acitavted')
    else:
        print('CPU Mode Acitavted')

    root_path=os.getcwd()
    folder_dataset_train_path=os.path.join(root_path,args.training_dir_name,args.source_type_train)
    folder_dataset_test=os.path.join(root_path,args.test_dir_name,args.source_type_test)
    print(folder_dataset_train_path)
    # 定义文件dataset
    folder_dataset_train = glob.glob(folder_dataset_train_path)
    folder_dataset_test = glob.glob(folder_dataset_test)
    # 定义预处理方式
    transform_train = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])
    transform_test = transforms.Compose([transforms.ToTensor(),transforms.Normalize([0.5], [0.5])])
    # transform_train = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5]),
    #                                       transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5,
    #                                                              hue=0.5)])
    # transform_test = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5]),
    #                                      transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5)])
    # 定义数据集
    dataset_train = GetDataset(imageFolderDataset=folder_dataset_train,
                               transform=transform_train)
    dataset_test = GetDataset(imageFolderDataset=folder_dataset_test[0:16],
                              transform=transform_test)

    # 数据集loader
    train_loader = DataLoader(dataset_train,
                              shuffle=True,
                              batch_size=args.batch_size)

    test_loader = DataLoader(dataset_test,
                             shuffle=True,
                             batch_size=args.batch_size)
    # model = network.DNWithCA(trainmode=True)
    # model = orinet_reviseatt.DNWithCA(trainmode=True)
    model = unetplusplus.NestedUNet(train_mode=True)
    # model=sesf_my.SESFuseNet(train_mode=True)

    if torch.cuda.device_count() > 1:
        model = nn.DataParallel(model)
        model.cuda()

    #Adam
    optimizer = optim.AdamW(model.parameters(), lr=args.lr,
                           betas=args.betas, eps=args.eps, weight_decay=args.weight_decay)
    scheduler=lr_scheduler.ExponentialLR(optimizer,gamma=args.gamma)

    def train(img):
        model.train()
        if torch.cuda.is_available():
            img = img.cuda()
        critertion1 = nn.MSELoss()
        critertion2 = myloss.SSIM()
        critertion3 = myloss.Gradient_Loss()
        critertion4 = myloss.SF_Loss()

        net_out = model(img)
        loss1 = critertion1(img, net_out)
        loss2 = 1 - critertion2(img, net_out)
        loss3 = critertion3(img, net_out)
        loss4 = critertion4(img, net_out)
        loss=args.loss_weight[0]*loss1+args.loss_weight[1]*loss2+args.loss_weight[2]*loss3+args.loss_weight[3]*loss4
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        return loss

    def test(img):
        model.eval()
        if torch.cuda.is_available():
            img = img.cuda()
        critertion1 = nn.MSELoss()
        critertion2 = myloss.SSIM()
        critertion3 = myloss.Gradient_Loss()
        critertion4 = myloss.SF_Loss()

        net_out = model(img)
        loss1 = critertion1(img, net_out)
        loss2 = 1 - critertion2(img, net_out)
        loss3 = critertion3(img, net_out)
        loss4 = critertion4(img, net_out)
        loss = args.loss_weight[0] * loss1 + args.loss_weight[1] * loss2 + args.loss_weight[2] * loss3 + \
               args.loss_weight[3] * loss4

        return loss
    #####
    for epoch in range(args.epochs):

        t1=time.time()
        running_train_loss = 0
        running_val_loss = 0
        tqdm_bar_train = tqdm(train_loader)
        for batch_idx, img in enumerate(tqdm_bar_train):
            train_loss = train(img)
            torch.cuda.synchronize()  # 确保数据正确
            running_train_loss += train_loss.item()
            tqdm_bar_train.set_description(
                f'Epoch {epoch}, Step {batch_idx}, Train Loss {train_loss.item():.4f}')
        print('finish train epoch: [{}/{}] costs:{}  avg_loss:{}'.format(epoch + 1 ,args.epochs,(time.time() - t1),(running_train_loss/len(train_loader))))
        scheduler.step()
        if (epoch + 1) % args.model_save_fre == 0:
            torch.save(model.state_dict(), 'models/{}/model_{}.pth'.format(args.name,(epoch + 1)))
        writer.add_scalar('training loss(epoch)', running_train_loss / len(train_loader), epoch)

        #验证
        best_loss = float('inf')  # For save best
        best_epoch = 0

        t1 = time.time()
        tqdm_bar_val = tqdm(test_loader)
        for batch_idx, img in enumerate(tqdm_bar_val):
            val_loss = test(img)
            running_val_loss += val_loss.item()
            tqdm_bar_val.set_description(
                f'Epoch {epoch}, Step {batch_idx}, Test Loss {val_loss.item():.4f}')
        writer.add_scalar('val loss(epoch)', running_val_loss / len(test_loader), epoch)
        print('finish val epoch: [{}/{}] costs:{}  avg_loss:{}'.format((epoch + 1),args.epochs,(time.time() - t1),(running_val_loss/len(test_loader))))
        if running_val_loss < best_loss:
            best_loss = running_val_loss
            best_epoch=epoch
            best_model = model.state_dict()
    writer.close()
    torch.save(best_model, 'models/{}/bestmodel_{}.pth'.format(args.name, str(best_epoch)))
if __name__ == '__main__':
    main()
