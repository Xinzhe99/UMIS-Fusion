import pandas as pd
import DNWithCA_V2
import myloss
import time
import os
import argparse
from tqdm import tqdm
import joblib
import glob
from collections import OrderedDict
import torch
import torch.backends.cudnn as cudnn
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from my_data_driven import GetDataset
import matplotlib.pyplot as plt
from datetime import datetime

def parse_args():  # 参数解析器
    parser = argparse.ArgumentParser()
    # 增加属性
    parser.add_argument('--name', default='IMG1_100epoch_1_3_1_2_no_medblur', help='model name: (default: arch+timestamp)')
    parser.add_argument('--epochs', default=100, type=int)  # 原来是100
    parser.add_argument('--batch_size', default=16, type=int)
    parser.add_argument('--lr', '--learning-rate', default=5e-4, type=float)  # 5e-4
    # parser.add_argument('--weight', default=[0.16, 0.84], type=float)
    parser.add_argument('--gamma', default=0.9, type=float)  # ExponentialLR gamma
    parser.add_argument('--betas', default=(0.9, 0.999), type=tuple)
    parser.add_argument('--eps', default=1e-8, type=float)
    parser.add_argument('--weight-decay', default=5e-4, type=float)  # 5e-4
    parser.add_argument('--training_dir',default="train_dataset/",type=str)
    parser.add_argument('--test_dir', default="test_dataset/", type=str)
    parser.add_argument('--loss_weight',default=[1,3,1,2],type=list,help='mse;ssim;gra;sf')
    parser.add_argument('--source_type', default='*.Bmp', type=str)
    args = parser.parse_args()  # 属性给与args实例：add_argument 返回到 args 子类实例
    return args

def main():
    args = parse_args()
    if not os.path.exists('models/%s' % args.name):
        os.makedirs('models/%s' % args.name)  # 创建文件夹保存模型
    print('Config -----')
    for arg in vars(args):
        print('%s: %s' % (arg, getattr(args, arg)))  # 打印参数配置
    print('------------')
    with open('models/%s/args.txt' % args.name, 'w') as f:  # 写入参数文件
        for arg in vars(args):
            print('%s: %s' % (arg, getattr(args, arg)), file=f)
    joblib.dump(args, 'models/%s/args.pkl' % args.name)
    cudnn.benchmark = True
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    if torch.cuda.is_available():
        print('GPU Mode Acitavted')
    else:
        print('CPU Mode Acitavted')
    # 定义文件dataset
    folder_dataset_train = glob.glob(args.training_dir + args.source_type)
    folder_dataset_test = glob.glob(args.test_dir + args.source_type)
    # 定义预处理方式
    transform_train = transforms.Compose([transforms.ToTensor(),
                                          transforms.Normalize((0.5), (0.5))])
    transform_test = transforms.Compose([transforms.ToTensor(),
                                         transforms.Normalize((0.5), (0.5))])
    # 定义数据集
    dataset_train = GetDataset(imageFolderDataset=folder_dataset_train,
                               transform=transform_train)
    dataset_test = GetDataset(imageFolderDataset=folder_dataset_test,
                              transform=transform_test)

    # 数据集loader
    train_loader = DataLoader(dataset_train,
                              shuffle=True,
                              batch_size=args.batch_size)

    test_loader = DataLoader(dataset_test,
                             shuffle=True,
                             batch_size=args.batch_size)
    net = DNWithCA_V2.DNWithCA(trainmode=True)
    if torch.cuda.is_available():
        net=net.cuda()
        net.cuda()
    else:
        net=net
    critertion1 = nn.MSELoss()
    critertion2= myloss.SSIM()
    critertion3=myloss.Gradient_Loss()
    critertion4 = myloss.SF_Loss()
    #Adam
    optimizer = optim.Adam(net.parameters(), lr=args.lr,
                           betas=args.betas, eps=args.eps, weight_decay=args.weight_decay)  # Adam法优化,filter是为了固定部分参数
    scheduler=lr_scheduler.ExponentialLR(optimizer,gamma=args.gamma)

    running_train_loss = 0
    running_val_loss = 0
    log = pd.DataFrame(index=[],
                       columns=['epoch',
                                'lr',
                                'train_loss',
                                'val_loss'])
    #visialize
    train_loss_list = []
    val_loss_list=[]
    #####
    for epoch in range(args.epochs):
        #训练
        net.train()
        t1=time.time()
        for i,in_img in tqdm(enumerate(train_loader),total=len(train_loader)):
            if torch.cuda.is_available():
                in_img=in_img.cuda()
            else:
                in_img = in_imghttps://github.com/Xinzhe99/temp_one_mask_fusion/blob/main/train
            net_out=net(in_img)
            loss1=critertion1(in_img,net_out)
            loss2=1-critertion2(in_img,net_out)
            loss3=critertion3(in_img,net_out)
            loss4 = critertion4(in_img, net_out)
            loss=args.loss_weight[0]*loss1+args.loss_weight[1]*loss2+args.loss_weight[2]*loss3+args.loss_weight[3]*loss4
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            running_train_loss+=loss.item()
            print("[epoch: %3d/%3d, progress: %5d/%5d] train loss: %5f " % (epoch + 1, args.epochs, (i + 1) * args.batch_size, len(dataset_train), loss.item()))
        print('finish train epoch: [{}/{}] costs:{}  avg_loss:{}'.format(epoch + 1 ,args.epochs,(time.time() - t1),(running_train_loss/len(train_loader))))
        scheduler.step()
        if (epoch + 1) % 20 == 0:#每20个epoch记录一次
            torch.save(net.state_dict(), 'models/{}/model_{}.pth'.format(args.name,(epoch + 1)))
        train_loss_list.append(running_train_loss/len(train_loader))
        train_log = OrderedDict([('train_loss', running_train_loss/len(train_loader))])
        running_train_loss = 0
        #验证
        net.eval()
        with torch.no_grad():
            t1 = time.time()
            for i, in_img in tqdm(enumerate(test_loader), total=len(test_loader)):
                if torch.cuda.is_available():
                    in_img = in_img.cuda()
                else:
                    in_img = in_img
                net_out = net(in_img)
                loss1 = critertion1(in_img, net_out)
                loss2 = 1-critertion2(in_img, net_out)
                loss3 = critertion3(in_img, net_out)
                loss4 = critertion4(in_img, net_out)
                loss=args.loss_weight[0]*loss1+args.loss_weight[1]*loss2+args.loss_weight[2]*loss3+args.loss_weight[3]*loss4
                running_val_loss += loss.item()
                print("[epoch: %3d/%3d, batch: %5d/%5d] test loss: %5f " % (epoch + 1, args.epochs, (i + 1) * args.batch_size, len(dataset_test), loss.item()))
        val_log = OrderedDict([('val_loss', running_val_loss / len(test_loader))])
        val_loss_list.append(running_val_loss / len(test_loader))
        print('finish val epoch: [{}/{}] costs:{}  avg_loss:{}'.format((epoch + 1),args.epochs,(time.time() - t1),(running_val_loss/len(test_loader))))
        running_val_loss = 0

        tmp = pd.Series([
            epoch + 1,
            scheduler.get_last_lr(),
            train_log['train_loss'],
            val_log['val_loss'],
        ], index=['epoch', 'lr', 'train_loss', 'val_loss'])  # Series创建字典
        log = pd.concat([log, tmp], ignore_index=True)  # 新写的
        log.to_csv('models/%s/log.csv' % args.name, index=False)  # log:训练的日志记录
    #visialize part2
    x1 = range(0, args.epochs)
    x2 = range(0, args.epochs)
    y1 = train_loss_list
    y2 = val_loss_list
    plt.plot(x1, y1)
    plt.plot(x2, y2)
    plt.title('train_loss vs val_loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(["train", "val"], shadow=True, fancybox="blue")
    plt.savefig('./result/{}/train_loss_pic.jpg'.format(args.name))
if __name__ == '__main__':
    main()
