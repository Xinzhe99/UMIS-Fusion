# -*- coding: utf-8 -*-
# @Author  : XinZhe Xie
# @University  : ZheJiang University

import torch
import torch.nn as nn
import argparse
from torchvision import transforms
import time
import numpy as np
import os
import network
import glob
import cv2
from PIL import Image
import re
from datetime import datetime
from numba import jit
from numba.typed import List
def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument('--name', default='tbd',help='Output folder name')
    parser.add_argument('--fuse_Data_dir', default="tbd/", type=str,help='Enter the folder path of the image stack, each image name is best sorted by number e.g. 1.jpg,2.jpg......')
    parser.add_argument('--dict_path',default='tbd.pth', type=str,help='model path')
    parser.add_argument('--output_img_width', default='tbd', type=int,help='output width')
    parser.add_argument('--output_img_height', default='tbd', type=int,help='output height')
    parser.add_argument('--RemoveHighFreNoise', default=False, type=bool,help='remove noise,usually not used')
    parser.add_argument('--use_postprocess', default=False, type=bool,help='Whether to turn on post-processing')
    parser.add_argument('--use_fuzzy_optimization', default=False, type=bool,help='Whether to turn on fuzzy optimization (need to turn on post-processing at the same time)')
    parser.add_argument('--fuse_result_type', default='jpg', type=str,help='Format of output images')
    parser.add_argument('--source_type', default='*.jpg', type=str,help='Format of input images')
    parser.add_argument('--decisionmap_np_name', default='decision_map_np', type=str,help='Name of the output decision matrix')
    parser.add_argument('--sf_np_name', default='sf_map_np', type=str,help='Name of the SF matrix')
    return parser.parse_args()

@jit(nopython=True,cache=True)
def decisionmap_process(input_dm_np,k_size=None,use_fuzzy_op=None):
    img_height,img_width = input_dm_np.shape[0], input_dm_np.shape[1]
    padding_len = k_size // 2
    pad_img = np.zeros((img_height + 2 * padding_len, img_width + 2 * padding_len)).astype(np.int64)
    for i in range(pad_img.shape[1]):
        for j in range(pad_img.shape[0]):
            if i > padding_len - 1 and j > padding_len - 1 and i < pad_img.shape[1] - padding_len and j < pad_img.shape[0] - padding_len:
                pad_img[j][i] = int(input_dm_np[j - padding_len][i - padding_len])
            else:
                pad_img[j][i] = -1
    new_img = np.zeros((img_height, img_width)).astype(np.int64)
    for i in range(img_height):
        for j in range(img_width):
            #get original Value
            original_Value = pad_img[i + padding_len, j + padding_len]
            #get matrix
            moving_matrix=pad_img[i:i+2*padding_len+1,j:j+2*padding_len+1].flatten()
            #delete pidding value -1
            moving_matrix = moving_matrix[moving_matrix != -1]
            #get max min ,med,most_fre
            moving_most_fre = np.argmax(np.bincount(moving_matrix))
            if use_fuzzy_op==True:
                new_img[i][j] = int(np.median(moving_matrix))
            else:
                if original_Value == moving_most_fre:
                    new_img[i][j] = original_Value
                else:
                    new_img[i][j] = moving_most_fre
    return new_img

@jit(nopython=True,cache=True)
def Final_fusion(in_img_cv_list, in_decisionmap,height,width):  # Function is compiled and runs in machine code
    pic_fusion = np.zeros((height, width, 3), dtype=np.int64)
    pic_fusion_height = pic_fusion.shape[0]
    pic_fusion_width = pic_fusion.shape[1]
    pic_fusion_channels = pic_fusion.shape[2]
    for row in range(pic_fusion_height):
            for col in range(pic_fusion_width):
                    for channel in range(pic_fusion_channels):
                        pic_fusion[row, col, channel] = in_img_cv_list[in_decisionmap[row, col]][row, col, channel]
    return pic_fusion

@jit(nopython=True,cache=True)
def Generate_decisionmap(sf_list):
    sf_numba_list = List(sf_list)
    sf_num_np = np.zeros(shape=((height, width)))
    decisionmap_np = np.zeros((height, width),dtype=np.int64)
    for i in range(len(sf_numba_list)):
        for a in range(sf_num_np.shape[0]):
            for b in range(sf_num_np.shape[1]):
                if sf_numba_list[i][a][b]>=sf_num_np[a][b]:
                    sf_num_np[a][b]=sf_numba_list[i][a][b]
                    decisionmap_np[a][b]=int(i)
    return decisionmap_np,sf_num_np

if __name__ == '__main__':
    args = parse_args()
    width = args.output_img_width
    height = args.output_img_height
    t1 = time.time()
    if torch.cuda.is_available():
        print('GPU Mode Acitavted')
    else:
        print('CPU Mode Acitavted')
    if not os.path.exists('result/%s'% args.name):
        os.makedirs('result/%s' % args.name)
    pic_sequence_list = glob.glob(args.fuse_Data_dir + args.source_type)
    pic_sequence_list.sort(key=lambda x: int(str(re.findall("\d+", x.split('/')[-1])[-1])))#Sort by the number in the file name
    img_cv_list=[None]*(len(pic_sequence_list))
    img_list=[None]*(len(pic_sequence_list))
    sf_list=[None] * (len(pic_sequence_list))

    model = network.DNWithCA(trainmode=False)
    num_gpus = torch.cuda.device_count()

    # model = nn.DataParallel(model)#todo Parallelization training
    if num_gpus > 1:
        device = torch.device("cuda")
    else:
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    data_transforms = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize([0.5], [0.5])])

    model.to(device)
    model.load_state_dict(torch.load(args.dict_path, map_location=device))
    model.eval()

    #read sf list
    for i in range(len(pic_sequence_list)):
        img_list[i]=Image.open(pic_sequence_list[i]).convert('L').resize((width,height),Image.Resampling.BILINEAR)
        if args.RemoveHighFreNoise==True:
            img_list[i] = np.array(img_list[i])
            img_list[i] = cv2.medianBlur(img_list[i], 5)
            img_list[i] = Image.fromarray(img_list[i].astype('uint8'))
        else:
            pass
        img_list[i] = data_transforms(img_list[i]).unsqueeze(0).to(device)
        sf_list[i] = model(img_list[i]).cpu().numpy()
        print('finish send no.{} pic into the net'.format(str(i)))

    #generate initial decision map
    decisionmap_numpy,sf_numpy=Generate_decisionmap(sf_list)

    #save decision map numpy
    decisionmap_np_dst='result/{}/{}'.format(args.name,args.decisionmap_np_name + datetime.now().strftime("%Y_%m_%d_%H_%M_%S")+'.npy')
    sf_np_dst = 'result/{}/{}'.format(args.name, args.sf_np_name + datetime.now().strftime(
        "%Y_%m_%d_%H_%M_%S") + '.npy')
    np.save(decisionmap_np_dst,decisionmap_numpy)
    np.save(sf_np_dst, sf_numpy)
    print('Finish gernerate initial decision map,and save in {}'.format(decisionmap_np_dst))
    print('Finish gernerate sf map,and save in {}'.format(sf_np_dst))

    #Optimization Decision Map
    if args.use_postprocess==True:
        Post_processing_core_size=min(height,width)//20 if (min(height,width)//20)%2!=0 else (min(height,width)//20)-1
        decisionmap_np_afterprocess = decisionmap_process(decisionmap_numpy,k_size=Post_processing_core_size,use_fuzzy_op=args.use_fuzzy_optimization)
        decisionmap_np_optimized_dst = 'result/{}/{}'.format(args.name,
                                                             args.decisionmap_np_name + datetime.now().strftime(
                                                                 "%Y_%m_%d_%H_%M_%S") + 'optimized' + '.npy')
        np.save(decisionmap_np_optimized_dst, decisionmap_np_afterprocess)
        print('Finish gernerate Final decision map,and save in {}'.format(decisionmap_np_optimized_dst))
    else:
        decisionmap_np_afterprocess =decisionmap_numpy

    #fusion step1:create pic list which could be read by cv2
    for i in range(len(pic_sequence_list)):
        img_cv_list[i]=cv2.imread(pic_sequence_list[i])
        img_cv_list[i]=cv2.resize(img_cv_list[i],(width,height))

    #fusion step2:create final pic
    pic_fusion=Final_fusion(img_cv_list,decisionmap_np_afterprocess,height,width)
    print(time.time()-t1)
    save_path = "result/{}/fusion_result{}.{}".format(args.name, datetime.now().strftime("%Y_%m_%d_%H_%M_%S"),
                                                      args.fuse_result_type)
    cv2.imwrite(save_path, pic_fusion)
    print('Fusion Done!,and save in {}'.format(save_path))
